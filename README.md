# ğŸ–¼ï¸ Classification d'Images CIFAR-10 avec CNN

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Description

Projet du module  **Deep Learning** rÃ©alisÃ© dans le cadre du Master IMSD Ã  l'ENSA Khouribga. Ce projet implÃ©mente un **rÃ©seau de neurones convolutif (CNN)** pour la classification d'images du dataset CIFAR-10.

### ğŸ¯ Objectif

DÃ©velopper un modÃ¨le robuste capable de classifier automatiquement des images basse rÃ©solution (32x32 pixels) en 10 catÃ©gories distinctes avec une prÃ©cision supÃ©rieure Ã  71%.

---

## ğŸ“Š Dataset CIFAR-10

<div align="center">

| CaractÃ©ristique | Valeur |
|----------------|---------|
| **Images Total** | 60 000 (RGB) |
| **RÃ©solution** | 32Ã—32 pixels |
| **Classes** | 10 classes distinctes |
| **Split** | 50k Train / 10k Test |

</div>

### ğŸ·ï¸ Classes

- âœˆï¸ Avion (Airplane)
- ğŸš— Automobile
- ğŸ¦ Oiseau (Bird)
- ğŸ± Chat (Cat)
- ğŸ¦Œ Cerf (Deer)
- ğŸ• Chien (Dog)
- ğŸ¸ Grenouille (Frog)
- ğŸ´ Cheval (Horse)
- ğŸš¢ Bateau (Ship)
- ğŸšš Camion (Truck)

### ğŸ” DÃ©fis du Dataset

- **Faible rÃ©solution** : Perte de texture et dÃ©tails fins
- **ArriÃ¨re-plans complexes** : Ã‰lÃ©ments parasites dans l'image
- **VariabilitÃ© de posture** : Angles et positions variÃ©s

---

## ğŸ—ï¸ Architecture du ModÃ¨le

### Structure CNN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extraction des CaractÃ©ristiques        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Bloc 1: DÃ©tection Initiale             â”‚
â”‚  â€¢ Conv2D (32 filtres, 3Ã—3, ReLU)       â”‚
â”‚  â€¢ Conv2D (32 filtres, 3Ã—3, ReLU)       â”‚
â”‚  â€¢ MaxPooling2D (2Ã—2)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Bloc 2: ComplexitÃ© Accrue              â”‚
â”‚  â€¢ Conv2D (64 filtres, 3Ã—3, ReLU)       â”‚
â”‚  â€¢ Conv2D (64 filtres, 3Ã—3, ReLU)       â”‚
â”‚  â€¢ MaxPooling2D (2Ã—2)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classification et Sortie               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Flatten & Dense (64 unitÃ©s)          â”‚
â”‚  â€¢ Dropout (0.5)                        â”‚
â”‚  â€¢ Softmax (10 classes)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total ParamÃ¨tres:** ~328 000

---

## ğŸ”§ PrÃ©traitement & Pipeline

### 1. Normalisation
```python
# Conversion [0, 255] â†’ [0, 1]
X_train = X_train.astype('float32') / 255.0
```

### 2. One-Hot Encoding
```python
# Labels catÃ©goriels
y_train = to_categorical(y_train, 10)
```

### 3. Data Augmentation

Techniques appliquÃ©es pour amÃ©liorer la gÃ©nÃ©ralisation :

| Technique | ParamÃ¨tre |
|-----------|-----------|
| **Rotation** | Â±15Â° |
| **Translation** | Shift horizontal/vertical |
| **Flip Horizontal** | Oui |
| **Zoom** | Facteur alÃ©atoire |

**Objectif:** Forcer l'apprentissage de caractÃ©ristiques invariantes.

---

## ğŸ“ EntraÃ®nement

### HyperparamÃ¨tres

| ParamÃ¨tre | Valeur TestÃ©e | **SÃ©lection Finale** |
|-----------|---------------|----------------------|
| Dropout (Conv) | 0.15, 0.3 | **0.3** |
| Dropout (Dense) | 0.3, 0.5 | **0.5** |
| Filtres (Couche 1) | 32 vs 64 | **32** |
| Learning Rate | N/A | **0.0005** (avec Scheduler) |

### StratÃ©gies de RÃ©gularisation

- âœ… **Dropout** : Force la redondance des neurones
- âœ… **Early Stopping** : ArrÃªt au pic de performance validation
- âœ… **Optimiseur** : Adam (adaptatif)

**MÃ©thode d'optimisation:** Grid/Random Search

---

## ğŸ“ˆ RÃ©sultats

### Performance Globale

<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Accuracy Globale : 71.1%      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

### F1-Scores par Classe

| Classe | F1-Score | Performance |
|--------|----------|-------------|
| ğŸš¢ Bateau | 0.83 | â­â­â­ Excellent |
| ğŸš— Automobile | 0.82 | â­â­â­ Excellent |
| ğŸšš Camion | 0.76 | â­â­ Bon |
| ğŸ¦ Oiseau | 0.57 | â­ Moyen |
| ğŸ± Chat | 0.50 | â­ Moyen |

**Observation:** Le modÃ¨le excelle sur les structures rigides (vÃ©hicules) mais peine sur les formes organiques (animaux).

### Courbes d'Apprentissage

- âœ… **Convergence saine** : Pas de surapprentissage majeur
- âœ… **Ã‰cart Train/Val stable** : GÃ©nÃ©ralisation satisfaisante

---

## ğŸ”¬ Analyse des Erreurs

### Matrice de Confusion

**Principales confusions identifiÃ©es:**

1. **SÃ©mantique (35%)** : Chat â†” Chien, Cerf â†” Cheval
2. **Silhouettes similaires** : Grenouille â†” Cheval (formes proches Ã  basse rÃ©solution)

### Explainability : Saliency Maps

Les cartes de saillance rÃ©vÃ¨lent que le modÃ¨le :
- âœ… Se focalise sur l'**objet central**
- âœ… Ignore efficacement l'**arriÃ¨re-plan**
- âš ï¸ Peut se tromper sur des **patterns de texture** ambigus

---

## ğŸ“Š Comparaison Architecturale

### CNN vs MLP

| Architecture | Accuracy | Avantage |
|--------------|----------|----------|
| **MLP** | 53.7% | Perte de structure spatiale |
| **CNN** | **71.1%** | PrÃ©servation des motifs locaux (2D) |

**Gain relatif:** +32% grÃ¢ce aux convolutions

---

## ğŸš€ Perspectives d'AmÃ©lioration

### 1. Architectures Profondes
- ğŸ”¹ **ResNet** : Connexions rÃ©siduelles pour capturer les dÃ©tails fins
- ğŸ”¹ **VGG** : Profondeur accrue

### 2. Transfer Learning
- ğŸ”¹ Utilisation de poids prÃ©-entraÃ®nÃ©s sur **ImageNet**
- ğŸ”¹ Fine-tuning des derniÃ¨res couches

### 3. Super-Resolution
- ğŸ”¹ **Augmenter la nettetÃ©** avant classification
- ğŸ”¹ Techniques comme SRGAN ou ESRGAN

---

## ğŸ“ Structure du Projet

```
projet-deep-learning/
â”‚
â”œâ”€â”€ ğŸ““ ensa-master-imsd-dl-projet-3-cifar10__2_.ipynb   # Notebook principal
â”œâ”€â”€ ğŸ“„ DL_-_Rapport.docx                                 # Rapport dÃ©taillÃ©
â”œâ”€â”€ ğŸ¯ CNN_Classification_Low_Resolution_Imagery.pdf     # PrÃ©sentation
â”œâ”€â”€ ğŸ“– README.md                                         # Ce fichier
â”‚

```

---

## ğŸ› ï¸ Installation & Utilisation

### PrÃ©requis

```bash
Python >= 3.8
TensorFlow >= 2.8
Keras
NumPy
Matplotlib
Seaborn
```

### Installation

```bash
# Cloner le repository
git clone https://github.com/VOTRE_USERNAME/cifar10-cnn-classification.git
cd cifar10-cnn-classification

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### ExÃ©cution

```bash
# Lancer Jupyter Notebook
jupyter notebook ensa-master-imsd-dl-projet-3-cifar10__2_.ipynb
```

Ou exÃ©cuter directement :

```python
# Charger et entraÃ®ner le modÃ¨le
python train_model.py

# Ã‰valuer le modÃ¨le
python evaluate.py
```

---

## ğŸ“š RÃ©fÃ©rences

- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html) - Alex Krizhevsky
- [Deep Learning Book](https://www.deeplearningbook.org/) - Goodfellow et al.
- [TensorFlow Documentation](https://www.tensorflow.org/)
- [Keras API](https://keras.io/)

---

## ğŸ‘¥ Auteurs

  
ğŸ“ SARA MAGGGAG & ACHRAF MASNSARI  


---

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements


- ğŸ“š CommunautÃ© TensorFlow/Keras
- ğŸŒ Dataset CIFAR-10 par Alex Krizhevsky

---

<div align="center">

**â­ Si ce projet vous aide, n'hÃ©sitez pas Ã  lui donner une Ã©toile ! â­**

Made with â¤ï¸ and ğŸ§  

</div>
